{"/en/about/":{"data":{"":"Hey there! I‚Äôm thrilled you‚Äôve found your way to my little space on the web. As a frontend developer venturing into the full-stack world, I share my thoughts on technology, life‚Äôs adventures, and the occasional random musings that keep me up at night. Whether you‚Äôre a fellow tech enthusiast, a curious wanderer, or someone who just stumbled upon this page ‚Äì welcome!","built-with#Built With":"This site is crafted with modern web technologies:\nBuilt with Hugo, a lightning-fast static site generator Styled with Hextra theme for clean, minimalist design Deployed on Vercel for optimal performance Domain managed by Cloudflare for enhanced security and speed","open-source#Open Source":"This blog is open source. Feel free to explore the code and star the repository!\nüìÇ Source Code: RiverCui blog","tech-stack#Tech Stack":"üë©‚Äçüíª Frontend:\nJavaScript / TypeScript Vue.js / React.js / Next.js CSS, Sass, Tailwind CSS Webpack, Vite üõ†Ô∏è Currently Learning:\nNode.js / Go MySQL / MongoDB RESTful APIs System Design üíº Interested in working together? I‚Äôm always excited to:\nBuild amazing web applications Share knowledge through technical content Contribute to meaningful projects Help others learn and grow üìÆ Get in Touch:\nEmail: rivertsuiwork@gmail.com GitHub: Github LinkedIn: Linkedin Twitter / X: Twitter / X Feel free to reach out - I‚Äôm just a message away!"},"title":"About"},"/en/capture-https-request-with-mobile-device/":{"data":{"":"","#":" Note: This article was translated from Chinese to English by Claude AI (Anthropic).\nRecently, while working on a project reconstruction for my company, which originally had native Android and iOS applications, I decided to understand the business logic and write new code by capturing network packets while operating the business on a mobile phone, referencing existing documentation and code for reconstruction. This article explains how I used a computer and a mobile phone to capture network requests from mobile devices.\nFirst, let me introduce the tool ‚Äî Charles, a network packet capture tool that allows developers to view and monitor HTTP/HTTPS communication data, primarily designed for developers to debug and analyze web applications and mobile apps. You can visit the Charles website to download it, which supports Windows, macOS, and Linux.\nBasic Usage After installing Charles, you can follow these steps:\n1. Ensure your phone and computer are on the same local network 2. Run Charles on your computer (default port 8888) 3. Open WLAN settings on your phone Modify the following three items, referring to the Xiaomi phone screenshot below:\nProxy: Change to Manual\nHostname: Enter your computer‚Äôs IP\nPort: 8888 (8888 is Charles‚Äô default port, which can be modified in Charles‚Äô Proxy Settings if needed)\n4. Open the app you want to capture on your phone Now you can see Charles running normally and starting to capture HTTP requests.\nAlthough HTTP request capture works fine, you might, like me, need to capture HTTPS requests. At this point, Charles will show scrambled data due to HTTPS‚Äôs higher security. We need to provide a certificate to properly access the data.\nConfiguring to Capture HTTPS Requests Installing certificates on mobile devices:\n1. Configure Charles SSL Proxy -\u003e SSL Proxying Settings\nAdd *:443.\n2. Download Certificate from Charles Open Charles, Help -\u003e SSL Proxying, and since we‚Äôre using a phone, select Mobile Device here.\nCharles will show a prompt. Following the instructions, use your phone to visit chls.pro/ssl to download the certificate.\n3. Install Certificate on Phone Taking a Xiaomi phone as an example, running MIUI 13.0.7, here are the steps to install the certificate:\nSecurity -\u003e More Security Settings -\u003e Encryption \u0026 Credentials -\u003e Install Certificate -\u003e CA Certificate, then select and install the Charles certificate you just downloaded\nNow when you open Charles, you can see the captured HTTPS request information."},"title":"Capturing Mobile Device HTTPS Requests with Charles"},"/en/css-masonry/":{"data":{"":"","#":" Note: This article was translated from Chinese to English by Claude AI (Anthropic).\nThe Debate Around Masonry Recently, the WebKit team published an article titled Help us invent CSS Grid Level 3, aka ‚ÄúMasonry‚Äù layout, discussing the proposal for Masonry layout.\nMasonry refers to the stonework of buildings (as shown below).\nMasonry layout is a pattern similar to brick or stone walls, commonly known as waterfall layout. This layout style is very common, used by sites like Pinterest and Xiaohongshu.\nMasonry was initially proposed by the WebKit team, and you can find its usage on MDN (currently only supported by Safari and Firefox browsers). In WebKit‚Äôs article, they explained why they believe Masonry should be part of CSS Grid, discussed the feasibility of using an alternative display: masonry approach if adopted by the CSS Working Group, and sought advice from developers and designers.\nThe Chrome team recently responded with an article titled An alternative proposal for CSS masonry, explicitly stating that ‚Äúimplementing it as a part of the CSS Grid specification [..] would be a mistake‚Äù.\nHow to Use Masonry Although waterfall layouts are common, I‚Äôve never written one as a frontend engineer. Let‚Äôs take this opportunity to create a waterfall page using this new layout.\nFirst, let‚Äôs create an HTML file and add some images for the waterfall layout.\n\u003cdiv class=\"gallery-container\"\u003e \u003cfigure\u003e \u003cimg src=\"https://picsum.photos/seed/1715619706392/500/500\"\u003e \u003c/figure\u003e \u003cfigure\u003e \u003cimg src=\"https://picsum.photos/seed/1715619668573/500/1000\"\u003e \u003c/figure\u003e \u003cfigure\u003e \u003cimg src=\"https://picsum.photos/seed/1715619707240/500/500\"\u003e \u003c/figure\u003e \u003cfigure\u003e \u003cimg src=\"https://picsum.photos/seed/1715619669966/500/1000\"\u003e \u003c/figure\u003e \u003cfigure\u003e \u003cimg src=\"https://picsum.photos/seed/1715619687217/500/800\"\u003e \u003c/figure\u003e \u003cfigure\u003e \u003cimg src=\"https://picsum.photos/seed/1715619713060/500/500\"\u003e \u003c/figure\u003e \u003c/div\u003e Then add CSS, using grid-template-rows: masonry to create the waterfall layout.\nimg { width: 500px; object-fit: contain; border-radius: 15px; } .gallery-container { display: grid; grid-template-columns: repeat(3, 1fr); grid-gap: 1rem; grid-template-rows: masonry; } We can see that while the grid layout works, grid-template-rows: masonry doesn‚Äôt take effect, leaving large gaps between images.\nThis is because Masonry is currently an experimental feature, unsupported by most browsers. You can download Safari Technology Preview or Firefox Nightly to try this new feature.\nI‚Äôm using Safari TP, and as shown below, a simple waterfall layout is achieved.\nThanks to masonry, the entire implementation is very simple. Here‚Äôs the complete code: waterfall-demo\nMy Opinion When first using this new feature, some aspects were confusing.\nFirst, as a non-native English speaker, the word ‚Äúmasonry‚Äù is very unfamiliar, unlike common CSS terms like border, center, none which are self-explanatory. There‚Äôs a language barrier.\nSecond, using grid-template-columns/grid-template-rows with masonry goes against my intuition. Simply put, to achieve a vertical waterfall flow, you need to use grid-template-rows: masonry, while I instinctively thought it would be grid-template-columns. It‚Äôs similar to how a Windows user might initially struggle with scrolling on macOS.\nTo summarize, I have two suggestions for Masonry:\nReplace the word ‚Äúmasonry‚Äù with the more intuitive ‚Äúwaterfall‚Äù Like the Chrome team‚Äôs view, Masonry shouldn‚Äôt be part of Grid, but should be used independently as display: masonry. "},"title":"CSS Masonry"},"/en/docker-proxy-configuration/":{"data":{"":" Note: This article was translated from Chinese to English by Claude AI (Anthropic).\nDocker Desktop login failures can occur for many reasons. If you can log in to Docker Hub via web browser without issues but Docker Desktop login times out, it‚Äôs likely due to proxy settings. You can follow the method below to configure it.","image-acceleration#Image Acceleration":"When pulling images from Docker Hub in China, you might encounter difficulties. You can refer to China‚Äôs Docker Hub Mirror Accelerators to configure image acceleration.","login-issues#Login Issues":"First, you need to have a proxy (Google it yourself) and get its port number. For example, I use Clash, and in its settings, I can see the port number is 7897.\nOpen Docker Desktop settings, go to Resource -\u003e Proxies.\nEnable Manual Proxy configuration, add Web Server(HTTP) and Web Server(HTTPS), using your proxy port number.\nRestart Docker Desktop and you should be able to log in normally."},"title":"Docker Proxy Configuration (Resolving Login Issues)"},"/en/how-to-manage-files-on-cloud-storage-with-rclone/":{"data":{"":" Note: This article was translated from Chinese to English by Claude AI (Anthropic).\nIn modern data management, cloud storage has become indispensable. Whether for individual users or enterprises, cloud storage provides convenient storage and access methods. This article will introduce how to use Rclone, a powerful command-line tool, to manage Alibaba Cloud OSS (Object Storage Service) files.","common-operations-examples#Common Operations Examples":"List files in bucket rclone ls alioss:your-bucket-name Upload files to bucket rclone copy /path/to/local/file alioss:your-bucket-name Download files to local rclone copy alioss:your-bucket-name /path/to/local/dir Sync local directory with bucket rclone sync /path/to/local/dir alioss:your-bucket-name ","configuring-rclone-to-connect-to-alibaba-cloud-oss#Configuring Rclone to Connect to Alibaba Cloud OSS":"After installation, we need to configure Rclone to connect to Alibaba Cloud OSS. Open Terminal and enter the following command to start the configuration wizard:\nrclone config You‚Äôll see an interactive configuration interface:\nNo remotes found - make a new one n) New remote s) Set configuration password q) Quit config n/s/q\u003e Enter n and press Enter to create a new remote. Then follow the prompts to enter the following information:\nRemote name: e.g., alioss Storage type: enter 4 for Amazon S3 Compliant Storage Providers Service provider: enter 2 for Alibaba Cloud Object Storage System (OSS) formerly Aliyun Access Key ID and ACCESS Key Secret: obtain from Alibaba Cloud OSS console Endpoint: choose your OSS endpoint, e.g., oss-cn-shenzhen.aliyuncs.com Other options: configure as needed, usually default values are fine After configuration, save and exit.","installing-rclone#Installing Rclone":"First, we need to install Rclone. You can download the appropriate installation package for your operating system from the Rclone website and follow the installation steps.\nFor macOS users, you can install via brew:\nbrew install rclone For Windows users, you can download the .exe file and run the installer.","summary#Summary":"Rclone is a powerful tool that can help you efficiently manage files in Alibaba Cloud OSS or other cloud services. Through simple configuration and command-line operations, you can easily accomplish tasks like file upload, download, and synchronization. I hope this article helps you get started with Rclone and fully utilize its powerful features to manage your cloud storage files.","what-is-rclone#What is Rclone?":"Rclone is an open-source command-line program that supports various cloud storage services, including Google Drive, Amazon S3 (Alibaba Cloud OSS, Tencent COS, Huawei OBS, etc.), and Dropbox. It can be used for file synchronization, data backup, storage migration, and other file management tasks. Rclone offers rich features such as encryption, compression, multi-threaded downloads, making it ideal for efficient cloud storage file management.\nIt supports the following features:\nOn-demand copying, only copying changed files each time Resume transfer after power outage Compressed transfer "},"title":"How to Efficiently Manage Cloud Storage Files with Rclone"},"/en/https-for-local-development/":{"data":{"":" Note: This article was translated from Chinese to English by Claude AI (Anthropic).\nI recently developed a webpage with QR code scanning functionality, but the scanning feature requires camera access, which browsers only allow in HTTPS environments for security reasons. Therefore, to debug these features locally, we need to configure HTTPS for the local development server. The core solution to this problem is generating local certificates and self-signing them. While there are many methods available online, I‚Äôll introduce two approaches here that you can follow along with - they should be sufficient for basic development needs.","built-in-options-for-vue--react#Built-in Options for Vue / React":"Both React and Vue come with built-in options for enabling HTTPS, making it even simpler to use HTTPS protocol locally.\nTaking vite as an example again, the official documentation mentions that if you need valid certificates, you can use their plugin @vitejs/plugin-basic-ssl, which automatically creates and caches a self-signed certificate.\n1. Install Plugin @vitejs/plugin-basic-ssl: pnpm add @vitejs/plugin-basic/ssl -D 2. Configure vite After configuring vite, you can run it directly. Note that browsers might show security warnings because our self-signed certificates aren‚Äôt issued by a trusted certificate authority, but this won‚Äôt affect development use - just don‚Äôt use it in production environments.\n// vite.config.js export default defineConfig({ // ... plugins: [ // ... basicSsl(), ], server: { // ... https: true, }, }) ","mkcert#mkcert":"mkcert is a simplified local CA tool for generating valid local HTTPS certificates. Here are the steps to use mkcert and configure certificates:\n1. Installation If you‚Äôre using macOS and have homebrew installed, you can install it this way:\nbrew instal mkcert brew install nss # This step is needed if you have Firefox installed, otherwise you'll get an error If you‚Äôre using Windows, you can click here to view installation steps.\n2. Install Local CA mkcert -install 3. Create Certificate for localhost mkcert localhost 127.0.0.1 ::1 After successful creation, the Terminal will display the certificate location and expiration date:\nThe certificate is at \"./localhost+2.pem\" and the key at \"./localhost+2-key.pem\" ‚úÖ It will expire on 25 March 2026 üóì 4. Store Certificates in Your Project Create a new folder in your project directory to manage certificates.\nFor example, I created a cert folder in my project directory and moved the generated localhost+2.pem and localhost+2-key.pem into it.\n5. Configure vite to Use HTTPS My project stack is vue3 + vite, so I‚Äôm configuring the vite.config.js file. If you‚Äôre using other build tools (like vue-cli + webpack), the configuration method is similar - just refer to the official documentation for appropriate adjustments. Note: Remember to restart the service after modifying the configuration.\n// vite.config.js import fs from 'fs'; import path from 'path'; export default defineConfig({ // ... server: { // ... https: { key: fs.readFileSync(path.resolve(__dirname, 'cert/localhost+2-key.pem')), cert: fs.readFileSync(path.resolve(__dirname, 'cert/localhost+2.pem')), }, }, }) "},"title":"Generating Local Certificates with mkcert/Vite"},"/en/module-management/":{"data":{"":"","commonjs#\u003ccode\u003eCommonJS\u003c/code\u003e":"","differences-between-esm-and-cjs#Differences Between \u003ccode\u003eESM\u003c/code\u003e and \u003ccode\u003eCJS\u003c/code\u003e":"","es-modules#\u003ccode\u003eES Modules\u003c/code\u003e":"","esm-backward-compatibility#\u003ccode\u003eESM\u003c/code\u003e Backward Compatibility":" Note: This article was translated from Chinese to English by Claude AI (Anthropic).\nModularization and Its Benefits The biggest difference between Node.js and browser JavaScript is that Node.js is modular.\nModularization Modularization is a programming paradigm that breaks down large, complex program systems into smaller, more manageable and maintainable parts. In modularization, each module performs a specific function while minimizing direct interaction with other modules. This approach has many advantages:\nEncapsulation. Each module encapsulates data and functionality internally and provides interfaces for external interaction. This helps hide internal implementation details and reduces interdependencies between modules. Reusability. Modularization allows developers to reuse code blocks across multiple parts of a project, or across multiple projects or applications, reducing duplicate code and improving overall code quality. Maintainability and Readability. Modular code is typically easier to understand and maintain, with each module responsible for clearly defined functionality, making the code more intuitive and easier to manage. Independence. Loose coupling between modules ensures that modifying one module will not or minimally affect other modules, facilitating the addition, updating, and fixing of functionality. Node.js‚Äôs Module Choices When Node.js was first created, JavaScript didn‚Äôt have a standard module mechanism, so Node.js initially adopted CommonJS (abbreviated as CJS below). Later, when JavaScript‚Äôs standard module mechanism ES Modules (abbreviated as ESM below) was born, browsers gradually began supporting ESM. Before Node.js supported ESM, compilation tools like Babel and bundling tools like Webpack were already compiling standard ESM module mechanisms into Node.js‚Äôs CJS module mechanism. Subsequently, Node.js v13.2.0 also introduced the standard ESM mechanism while maintaining compatibility with early CJS.\nSo now when writing Node.js modules, we have 3 approaches:\nDirectly use ESM, feasible in Node.js versions after v13.2.0. Use ESM but compile to CJS through Babel. Use CJS, as Node.js will continue to support both ESM and CJS for a long time to come. ES Modules export for exporting, import for importing\nExport Syntax exporting declaration\nexport let a, b export const a = 1, b = 2 export function functionName () {} export class ClassName {} export const { a, b } = obj export const [ a, b ] = arr For example:\n// hello.mjs export const name = 'River' // index.mjs import { name } from './hello.mjs' export list\nexport { name1, name2 } export { variable1 as name1, variable2 as name2 } export { variable1 as 'string name' } export { name1 as default } For example:\n// hello.mjs const name = 'River' const sayHello = (text) =\u003e `Hello ${text}!` export { name, sayHello as default } // index.mjs import { name } from './hello.mjs' import sayHello from './hello.mjs' console.log(sayHello(name)) // Hello River! default exports\nexport default expression export default function functionName() {} export default class ClassName {} Additionally, there‚Äôs the aggregating syntax export ... from ..., which won‚Äôt be detailed here. For more information, see MDN-JavaScript-export.\nImport Syntax Based on the above export methods, we can see that exported APIs are either default or non-default. To summarize, there are two different import methods for these two types of APIs (see examples above):\nimport { API } from module-path // non-default API import defaultAPI from module-path // default API Of course, like export, import can also use as to rename APIs.\nimport { variable1 as name1 } from module-path import * as foo from module-path The above import * as foo can generate an object foo from exported APIs, and the default API becomes foo.default.\nFile Extensions Note that in Node.js, .js files use the CommonJS specification by default for defining modules, while .mjs files use the ES Modules specification. For detailed rules about enabling these two, see the nodejs doc.\nTo use ESM to define modules in .js files, you can set type: module in the package.json configuration file.\nCommonJS module.exports for exporting, require for importing\nExport Syntax module.exports module.exports = { name1, name2 } module.exports = { name1: variable1, name2: variable2 } // Different from ES Module's as usage exports exports.a = 1 exports.b = 2 exports.functionName = () =\u003e a + b For example:\n// hello.js const name = 'River' const sayHello = (text) =\u003e `Hello ${text}!` module.exports = { name, sayHello } // index.js const { name, sayHello } = require('./hello.js') console.log(sayHello(name)) exports.propertyName is an early usage; now we should preferably use module.exports = { propertyName }. Note that these two syntaxes cannot be used simultaneously, as exports.propertyName will be overwritten by module.exports = { propertyName }.\nImport Syntax const { API } = require(module-path) Differences Between ESM and CJS The loading mechanism is key to understanding the core features of these two module systems and represents their fundamental difference.\nCJS Dynamic Loading Runtime Loading. Module dependencies are resolved during code execution. This means require() function calls are processed during code execution, allowing flexible use of template strings for dynamic path concatenation, for example: const libPath = ENV.supportES6 ? './es6/' : './' const myLib = require(`${libPath}lib.js`) You can also load modules based on program logic and conditions. For example, you can call require() within an if statement to load different modules based on different conditions. let api; if(condition) { api = require('./foo'); } else { api = require('./bar'); } Synchronous Loading. When network delay isn‚Äôt a concern, especially in server-side JavaScript (Node.js), modules are generally loaded from the local file system, making synchronous loading feasible. ESM Static Loading Compile-time Loading. Module dependencies are determined at compile time. import and export must be placed at the top level and cannot be included in functions or conditional statements. Asynchronous Loading. Asynchronous loading allows code to continue executing while modules are downloading and processing, solving blocking issues but making module management more complex. Dynamic Loading with ESM While ESM doesn‚Äôt allow import statements with dynamic paths or within statement blocks, it does allow dynamic loading through the import() function, which is asynchronous.\nDynamic import() returns a Promise that resolves to all exports of the imported module. You need to use .then(), async/await or similar methods to handle the imported module. For example:\n(async function() { const { functionName } = await import('./myModules.mjs) functionName() }()) Use cases:\nConditional Loading For example: if(someCondition) { import('./myModules.mjs') .then(module =\u003e { module.functionName() }) } Performance Optimization. For example, when handling large modules, using code splitting and lazy loading to reduce initial load time and improve performance. ESM Backward Compatibility In the Node.js environment, ES Modules is backward compatible with CommonJS. APIs exported by CJS can also be imported using import(), but only as a default import. For example:\n// foo.js const a = 1 const b = 2 const c = () =\u003e a + b module.exports = { a, b, c } // bar.mjs import abc from './foo.js' console.log(abc.a, abc.b, abc.c()) // 1, 2, 3 In other words, module.exports is equivalent to:\nconst abc = { a, b, c } export default abc ","modularization-and-its-benefits#Modularization and Its Benefits":""},"title":"Module Management"},"/en/mysql/":{"data":{"basic-usage#Basic Usage":"Connect to MySQL mysql -u root -p Enter password:****** Basic Commands Show Database List SHOW DATABASES; Create Database CREATE DATABASE testdb; Use Database USE testdb; Create Table CREATE TABLE users ( id INT AUTO_INCREMENT PRIMARY KEY, name VARCHAR(100), email VARCHAR(100) ); View Table Structure DESCRIBE users; Data Operations Insert Data INSERT INTO users (name, email) VALUES ('John Doe', 'john@example.com'); Query Data SELECT * FROM users; Update Data UPDATE users SET email = 'john.doe@example.com' WHERE name = 'John Doe'; Delete Data DELETE FROM users WHERE name = 'John Doe'; Common Features Conditional Queries SELECT * FROM users WHERE email LIKE '%@example.com'; Sorted Queries SELECT * FROM users ORDER BY name ASC; Aggregate Functions SELECT COUNT(*) FROM users; SELECT AVG(id) FROM users; Multi-table Operations Create Second Table CREATE TABLE orders ( order_id INT AUTO_INCREMENT PRIMARY KEY, user_id INT, product_name VARCHAR(100), FOREIGN KEY (user_id) REFERENCES users(id) ); Join Queries SELECT users.name, orders.product_name FROM users JOIN orders ON users.id = orders.user_id; The SELECT users.name, orders.product_name clause specifies the columns we want to extract from the database:\nThe name column from users table (users.name) The product_name column from orders table (orders.product.name) The FROM users clause specifies our first query table, the users table. The JOIN orders ON users.id = orders.user_id clause joins the two tables. It uses an inner join to associate the users table with the orders table. The join condition is users.id = orders.user_id. INNER JOIN returns all records from both tables that meet the condition. If a record has matching records in both users and orders tables, it will be included in the result set. In simple terms, this query returns all users who have orders and their order product names.\nFor example, given these two tables:\nusers table:\nid name 1 Alice 2 Bob 3 Charlie orders table:\norder_id user_id product_name 101 1 Laptop 102 1 SmartPhone 103 2 Tablet The query result will be:\nname product_name Alice Laptop Alice Smartphone Bob Tablet ","command-line-tools#Command Line Tools":"For all command line options, check the official documentation: mysql Client Commands\nHere are some common ones:\n\\g and \\G are both command terminators; alternatively, you can use ; to end commands.\n\\g # Send command to MySQL server \\G # Send command to MySQL server and format output \\c # Clear current input \\q # Exit MySQL ","common-issues#Common Issues":"","enter-mysql-cli#Enter MySQL CLI":" mysql -u root -p Enter the installation password to successfully enter MySQL CLI.","environment-variables#Environment Variables":"Check current shell\necho $SHELL If it shows /bin/bash, you‚Äôre using bash; if it shows /bin/zsh, you‚Äôre using zsh.\nFor bash:\n# 1. Edit vim ~/.bash_profile # 2. Add export PATH=${PATH}:/usr/local/mysql/bin # 3. Update source ~/.bash_profile For zsh:\n# 1. Edit vim ~/.zshrc # 2. Add export PATH=${PATH}:/usr/local/mysql/bin # 3. Update source ~/.zshrc ","error-1819-hy000-your-password-does-not-satisfy-the-current-policy-requirements#ERROR 1819 (HY000): Your Password Does Not Satisfy the Current Policy Requirements":"Running the following code will give an error:\nALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY 'admin' Error message: ERROR 1819 (HY000): Your password does not satisfy the current policy requirements. The password doesn‚Äôt meet security requirements. Change the password security requirements to fix this. Steps to resolve:\nLogin to MySQL\nmysql -u root -p Check current password policy\nSHOW VARIABLES LIKE 'validate_password%'; +-------------------------------------------------+--------+ | Variable_name | Value | +-------------------------------------------------+--------+ | validate_password.changed_characters_percentage | 0 | | validate_password.check_user_name | ON | | validate_password.dictionary_file | | | validate_password.length | 8 | | validate_password.mixed_case_count | 1 | | validate_password.number_count | 1 | | validate_password.policy | MEDIUM | | validate_password.special_char_count | 1 | +-------------------------------------------------+--------+ Modify current password policy\nSET GLOBAL validate_password.length=4; SET GLOBAL validate_password.policy=LOW; Now the password policy has been modified\n+-------------------------------------------------+-------+ | Variable_name | Value | +-------------------------------------------------+-------+ | validate_password.changed_characters_percentage | 0 | | validate_password.check_user_name | ON | | validate_password.dictionary_file | | | validate_password.length | 4 | | validate_password.mixed_case_count | 1 | | validate_password.number_count | 1 | | validate_password.policy | LOW | | validate_password.special_char_count | 1 | +-------------------------------------------------+-------+ Refresh privileges and try changing password again\nFLUSH PRIVILEGES ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY 'admin'; ","installation#Installation":"MySQL Community Server MySQL Community Server is the database server responsible for actually storing and managing data.\nDownload link: https://dev.mysql.com/downloads/mysql/\nSelect your version and operating system, then click the Download button. I‚Äôm using macOS 14 with an M1 chip, so I selected macOS 14 (ARM, 64-bit), DMG Archive for download.\nAfter installation, open System Settings, scroll to the bottom to find MySQL, and click the button to run the MySQL service.\nMySQL Workbench MySQL Workbench is a client application that you can use to connect to MySQL Community Server for database design, development, and management operations.\nMake sure to keep versions consistent. Download link: https://dev.mysql.com/downloads/workbench/\nAfter installation, open it, click on Connection or create a new one, enter the password and you‚Äôre good to go.","mysql-installation-and-usage#MySQL Installation and Usage":" Note: This article was translated from Chinese to English by Claude AI (Anthropic).\nMySQL Installation and Usage","no-apply-button-when-creating-table-in-mysql-workbench#No Apply Button When Creating Table in MySQL Workbench":"Version 8.0.36 has issues, replacing with 8.0.34 resolves this."},"title":"MySQL Installation and Basic Usage"},"/en/npm/":{"data":{"":" Note: This article was translated from Chinese to English by Claude AI (Anthropic).","npm#NPM":"NPM is the package manager that comes with Node.js.\nNode.js modules are broadly divided into internal modules and other modules. Internal modules are integrated within Node.js and don‚Äôt require referencing external JS files - they can be imported using require or import with the module name.\nFor example, the built-in fs module (for file operations) can be imported like this:\nconst fs = require('fs') Besides these built-in modules shown in the image, we often use many other modules in development. There are two ways to import them:\nImport using file paths\nFor example, in the project below, to import foo.js from directory a into bar.js in directory b:\n- a foo.js - b bar.js You can import it in bar.js like this:\nconst foo = require('../a/foo.js') Install modules into your project using NPM (by default in the node_modules directory) and reference them by package name in your code.\nnpm registry is NPM‚Äôs official repository where you can find needed packages and follow package documentation for installation and usage.\nFor example, the dayjs plugin can be installed using NPM:\nnpm install dayjs Usage:\nconst dayjs = require('dayjs') dayjs().format() When importing modules by package name, Node.js uses the resolve algorithm to first search the node_modules directory in the module‚Äôs location. If not found, it recursively searches node_modules in parent directories up to the root directory.\nThere‚Äôs a lot worth discussing about NPM - I‚Äôll create a separate topic for it in the future ‚úçÔ∏è."},"title":"NPM"},"/en/pre-knowledge-of-nodejs/":{"data":{"":" Note: This article was translated from Chinese to English by Claude AI (Anthropic).","basic-architecture#Basic Architecture":" Source: medium.com\nNode.js runs on top of the operating system, with its lower layer consisting of the Chrome V8 engine and some C/C++ libraries like libUv, c-ares, llhttp/http-parser, open-ssl, zlib, etc. LibUV handles event loops, while c-ares, llhttp/http-parser, open-ssl, zlib, and other libraries provide DNS resolution, HTTP protocol, HTTPS, and file compression capabilities.\nThe middle layer consists of Node.js Bindings, Node.js Standard Library, and C/C++ AddOns. The Node.js Bindings layer exposes the C/C++ library interfaces to the JS environment, while the Node.js Standard Library contains Node.js‚Äôs core modules. As for C/C++ AddOns, they allow users to bridge their own C/C++ modules to Node.js.\nAbove is Node.js‚Äôs API layer, which is what we primarily use when developing Node.js applications. Node.js applications ultimately run on top of the API layer.","nodejs-is-a-javascript-runtime-environment#Node.js is a JavaScript Runtime Environment":" Node.js¬Æ is an open-source, cross-platform JavaScript runtime environment.Source: Node.js\nNode.js is not a language but a platform, serving as a JavaScript runtime environment/host environment.\nAny discussion of Node.js inevitably involves the Chrome V8 engine. In 2009, Google began developing the Chrome browser, now the most widely used browser, and the Chrome V8 engine developed under Lars Bak‚Äôs leadership was born, launching a performance revolution for JavaScript. Node.js was built on the Chrome V8 engine. Later, Node.js creator Ryan Dahl also built Deno.\nToday, JavaScript‚Äôs architectural hierarchy has largely stabilized, as shown:\nSource: Juejin Books\nThe bottom layer is the scripting language specification (Spec), ECMAScript. Above that is language implementation, with JavaScript, JScript, ActionScript, etc., all implementing ECMAScript. At the engine level, besides Chrome V8 mentioned above, there are SpiderMonkey, QuickJS, JerryScript, and other common engines. The top layer consists of runtime environments, with Node.js, Chromium, Deno, and CloudFlare Workers based on Chrome V8, while Firefox is based on SpiderMonkey. ","use-cases#Use Cases":" Server-side\nNode.js provides event-driven and non-blocking interfaces for writing programs under high concurrency conditions. JavaScript‚Äôs anonymous functions, closures, callbacks, and other features were designed for event-driven programming.\nSome of Node.js‚Äôs built-in modules like http, net, fs were designed for server-side use. Whether it‚Äôs HTTP, TCP, UDP, or RPC services, Node.js can handle them all.\nDesktop Applications\nElectron.js, an open-source framework developed and maintained by the OpenJS Foundation, aims to create desktop applications using web technologies with the Chromium browser engine and Node.js runtime environment.\nSoftware like Visual Studio Code, 1Password, DingTalk are all developed using Electron.\nPC Games\nBesides writing browser-based games using WebGL or packaging games through Electron, JavaScript can also create genuine desktop games through Node.js bindings to use OpenGL or even DirectX.\nMachine Learning\npipcook\nWhile Node.js was originally conceived as a technology for building server-side applications, as a JavaScript runtime environment operating within the operating system, it has evolved into a platform spanning front-end and back-end development, traditional services and Serverless, tools, business applications, games, and more."},"title":"Node.js Prerequisites"}}